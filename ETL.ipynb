{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ETL.ipynb",
      "provenance": [],
      "mount_file_id": "1eQ3XPHTh_MxSElg8P_gjklFA0O28EO8n",
      "authorship_tag": "ABX9TyPGtPDyqwHpP+ansC5veqmG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/inna030/ETL/blob/main/ETL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install awscli"
      ],
      "metadata": {
        "id": "BezcXPd5cM0_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pipenv"
      ],
      "metadata": {
        "id": "K1OBVJ5YcOBX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64Uv0S5GaeH-",
        "outputId": "ef85aa46-a709-4343-f803-4c78ffa6f8de"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "lZl79x1scsdF",
        "outputId": "3b964ad3-6f78-4152-fde9-db4cedab79f6"
      },
      "source": [
        "'''import os\n",
        "!export AWS_SHARED_CREDENTIALS_FILE=/content/drive/My\\ Drive/config/awscli.ini\n",
        "path = \"/content/drive/My Drive/config/awscli.ini\"\n",
        "os.environ['AWS_SHARED_CREDENTIALS_FILE'] = path\n",
        "print(os.environ['AWS_SHARED_CREDENTIALS_FILE'])'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'import os\\n!export AWS_SHARED_CREDENTIALS_FILE=/content/drive/My\\\\ Drive/config/awscli.ini\\npath = \"/content/drive/My Drive/config/awscli.ini\"\\nos.environ[\\'AWS_SHARED_CREDENTIALS_FILE\\'] = path\\nprint(os.environ[\\'AWS_SHARED_CREDENTIALS_FILE\\'])'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install boto3"
      ],
      "metadata": {
        "id": "YxXhgYowcPoR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04E64YukSeb8"
      },
      "source": [
        "import boto3\n",
        "\n",
        "BUCKET_NAME = 'deutsche-boerse-xetra-pds' # replace with your bucket name\n",
        "\n",
        "# enter authentication credentials\n",
        "s3 = boto3.resource('s3', aws_access_key_id = '', \n",
        "                          aws_secret_access_key= '')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gAoXuGyej65a",
        "outputId": "4175b135-7109-499d-f319-615f726fa5f0"
      },
      "source": [
        "!aws s3 ls deutsche-boerse-xetra-pds/2021-08-05/ --no-sign-request"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-08-06 00:30:04        136 2021-08-05_BINS_XETR00.csv\n",
            "2021-08-06 00:30:05        136 2021-08-05_BINS_XETR01.csv\n",
            "2021-08-06 00:30:05        136 2021-08-05_BINS_XETR02.csv\n",
            "2021-08-06 00:30:05        136 2021-08-05_BINS_XETR03.csv\n",
            "2021-08-06 00:30:05        136 2021-08-05_BINS_XETR04.csv\n",
            "2021-08-06 00:30:05        136 2021-08-05_BINS_XETR05.csv\n",
            "2021-08-06 00:30:06        136 2021-08-05_BINS_XETR06.csv\n",
            "2021-08-06 00:30:06    1414574 2021-08-05_BINS_XETR07.csv\n",
            "2021-08-06 00:30:06    1212092 2021-08-05_BINS_XETR08.csv\n",
            "2021-08-06 00:30:07    1077607 2021-08-05_BINS_XETR09.csv\n",
            "2021-08-06 00:30:07    1014529 2021-08-05_BINS_XETR10.csv\n",
            "2021-08-06 00:30:07    1124025 2021-08-05_BINS_XETR11.csv\n",
            "2021-08-06 00:30:07     934216 2021-08-05_BINS_XETR12.csv\n",
            "2021-08-06 00:30:07    1248285 2021-08-05_BINS_XETR13.csv\n",
            "2021-08-06 00:30:08    1275513 2021-08-05_BINS_XETR14.csv\n",
            "2021-08-06 00:30:08    1171325 2021-08-05_BINS_XETR15.csv\n",
            "2021-08-06 00:30:08        136 2021-08-05_BINS_XETR16.csv\n",
            "2021-08-06 00:30:08        136 2021-08-05_BINS_XETR17.csv\n",
            "2021-08-06 00:30:08        136 2021-08-05_BINS_XETR18.csv\n",
            "2021-08-06 00:30:09        563 2021-08-05_BINS_XETR19.csv\n",
            "2021-08-06 00:30:09        136 2021-08-05_BINS_XETR20.csv\n",
            "2021-08-06 00:30:09        136 2021-08-05_BINS_XETR21.csv\n",
            "2021-08-06 00:30:09        136 2021-08-05_BINS_XETR22.csv\n",
            "2021-08-06 00:30:10        136 2021-08-05_BINS_XETR23.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ybKLEj3H1aT",
        "outputId": "c5dcd160-2654-48d0-af0e-7a757a48f4bb"
      },
      "source": [
        "!pip install pandas"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.19.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkJXOlXXlWsw"
      },
      "source": [
        "from io import StringIO,BytesIO\n",
        "from datetime import datetime,timedelta"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdpbRSFkQ4uW"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJEgseShDVR1"
      },
      "source": [
        "def read_csv_to_df(bucket, key, decoding = 'utf-8', sep = ','):\n",
        "    csv_obj = bucket.Object(key=key).get().get('Body').read().decode(decoding)\n",
        "    data = StringIO(csv_obj)\n",
        "    df = pd.read_csv(data, delimiter=sep)\n",
        "    return df\n",
        "\n",
        "def write_df_to_s3(bucket, df, key):\n",
        "    out_buffer = BytesIO()\n",
        "    df.to_parquet(out_buffer, index=False)\n",
        "    bucket.put_object(Body=out_buffer.getvalue(), Key=key)\n",
        "    return True\n",
        "\n",
        "def write_df_to_s3_csv(bucket, df, key):\n",
        "    out_buffer = StringIO()\n",
        "    df.to_csv(out_buffer, index=False)\n",
        "    bucket.put_object(Body=out_buffer.getvalue(), Key=key)\n",
        "    return True\n",
        "\n",
        "def list_files_in_prefix(bucket, prefix):\n",
        "    files = [obj.key for obj in bucket.objects.filter(Prefix=prefix)]\n",
        "    return files\n",
        "\n",
        "meta_key='aws-s3.csv'\n",
        "bucket_name_trg='inna030'\n",
        "s3 = boto3.resource('s3', aws_access_key_id = '', \n",
        "                          aws_secret_access_key= '')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WjVDsgoqdykI"
      },
      "source": [
        "Application Layer - not core"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NstXZEd2LvM5"
      },
      "source": [
        "def return_date_list(bucket, arg_date, src_format, meta_key):\n",
        "    min_date = datetime.strptime(arg_date, src_format).date() - timedelta(days=1)\n",
        "    today = datetime.today().date()\n",
        "    try:\n",
        "        df_meta = read_csv_to_df(bucket, meta_key)\n",
        "        dates = [(min_date + timedelta(days=x)) for x in range(0, (today-min_date).days + 1)]\n",
        "        src_dates = set(pd.to_datetime(df_meta['source_date']).dt.date)\n",
        "        dates_missing = set(dates[1:]) - src_dates\n",
        "        if dates_missing:\n",
        "            min_date = min(set(dates[1:]) - src_dates) - timedelta(days=1)\n",
        "            return_dates = [date.strftime(src_format) for date in dates if date >= min_date]\n",
        "            return_min_date = (min_date + timedelta(days=1)).strftime(src_format)\n",
        "        else:\n",
        "            return_dates = []\n",
        "            return_min_date = datetime(2200, 1, 1).date()\n",
        "    except bucket.session.client('s3').execptions.NoSuchKey:\n",
        "        return_dates = [(min_date + timedelta(days=x)).strftime(src_format) for x in range(0, (today-min_date).days + 1)]\n",
        "        return_min_date = arg_date\n",
        "    return return_min_date, return_dates\n",
        "\n",
        "def update_meta_file(bucket, meta_key, extract_date_list):\n",
        "    df_new = pd.DataFrame(columns=['source_date', 'datetime_of_processing'])\n",
        "    df_new['source_date'] = extract_date_list\n",
        "    df_new['datetime_of_processing'] = datetime.today().strftime('%Y-%m-%d')\n",
        "    df_old = read_csv_to_df(bucket, meta_key)\n",
        "    df_all = pd.concat([df_old, df_new])\n",
        "    write_df_to_s3_csv(bucket, df_all, meta_key)\n",
        "    \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5z-bOUEyxam8"
      },
      "source": [
        "Adapter Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfvQPICXrSX-"
      },
      "source": [
        "def read_csv_to_df(bucket,key,decoding='utf-8',sep=','):\n",
        "  csv_obj=bucket.Object(key=key).get().get('Body').read().decode(decoding)\n",
        "  data=StringIO(csv_obj)\n",
        "  df=pd.read_csv(data,delimiter=sep)\n",
        "  return df\n",
        "\n",
        "def write_df_to_s3(bucket,df,key):\n",
        "  out_buffer=BytesIO()\n",
        "  df_all.to_parquet(out_buffer,index=False)\n",
        "  bucket.put_object(Body=out_buffer.getvalue(),key=key)\n",
        "  return True\n",
        "\n",
        "\n",
        "def write_df_to_s3_csv(bucket,df,key):\n",
        "  out_buffer=BytesIO()\n",
        "  df_all.to_csv(out_buffer,index=False)\n",
        "  bucket.put_object(Body=out_buffer.getvalue(),key=key)\n",
        "  return True\n",
        "\n",
        "def list_files_in_prefix(bucket,prefix):\n",
        "  files=[i.key for i in bucket.objects.filter(Prefix=prefix)]\n",
        "  return files\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KDcX-1_1xh-9"
      },
      "source": [
        "Application Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inv_t2u6xjoR"
      },
      "source": [
        "def extract(bucket, date_list):\n",
        "    files = [key for date in date_list for key in list_files_in_prefix(bucket, date)]\n",
        "    df = pd.concat([read_csv_to_df(bucket, obj) for obj in files], ignore_index=True)\n",
        "    return df\n",
        "\n",
        "def transform_report1(df, columns, arg_date):\n",
        "    df = df.loc[:, columns]\n",
        "    df.dropna(inplace=True)\n",
        "    df['opening_price'] = df.sort_values(by=['Time']).groupby(['ISIN', 'Date'])['StartPrice'].transform('first')\n",
        "    df['closing_price'] = df.sort_values(by=['Time']).groupby(['ISIN', 'Date'])['StartPrice'].transform('last')\n",
        "    df = df.groupby(['ISIN', 'Date'], as_index=False).agg(opening_price_eur=('opening_price', 'min'), closing_price_eur=('closing_price', 'min'), minimum_price_eur=('MinPrice', 'min'), maximum_price_eur=('MaxPrice', 'max'), daily_traded_volume=('TradedVolume', 'sum'))\n",
        "    df['prev_closing_price'] = df.sort_values(by=['Date']).groupby(['ISIN'])['closing_price_eur'].shift(1)\n",
        "    df['change_prev_closing_%'] = (df['closing_price_eur'] - df['prev_closing_price']) / df['prev_closing_price'] * 100\n",
        "    df.drop(columns=['prev_closing_price'], inplace=True)\n",
        "    df = df.round(decimals=2)\n",
        "    df = df[df.Date >= arg_date]\n",
        "    return df\n",
        "\n",
        "def load(bucket, df, trg_key, trg_format, meta_key, extract_date_list):\n",
        "    key = trg_key + datetime.today().strftime(\"%Y%m%d_%H%M%S\") + trg_format\n",
        "    write_df_to_s3(bucket, df, key)\n",
        "    update_meta_file(bucket, meta_key, extract_date_list)\n",
        "    return True\n",
        "\n",
        "def etl_report1(src_bucket, trg_bucket, date_list, columns, arg_date, trg_key, trg_format, meta_key):\n",
        "    df = extract(src_bucket, date_list)\n",
        "    df = transform_report1(df, columns, arg_date)\n",
        "    extract_date_list = [date for date in date_list if date >= arg_date]\n",
        "    load(trg_bucket, df, trg_key, trg_format, meta_key, extract_date_list)\n",
        "    return True\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LIIapCJt43wb"
      },
      "source": [
        "Application layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5VrVitVH42g0"
      },
      "source": [
        "def return_date_list(bucket,arg_date,src_format):\n",
        "  min_date=datetime.strptime(arg_date,src_format).date()-timedelta(days=1)\n",
        "  today=datetime.today().date()\n",
        "  return today"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yK59vqXxyja"
      },
      "source": [
        "Main function entrypoint"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gsKMe7b3xx0k"
      },
      "source": [
        "def main():\n",
        "    # Parameters/Configurations\n",
        "    # Later read config\n",
        "    arg_date = '2021-08-09'\n",
        "    src_format = '%Y-%m-%d'\n",
        "    src_bucket = 'deutsche-boerse-xetra-pds'\n",
        "    trg_bucket = 'inna030'\n",
        "    columns = ['ISIN', 'Date', 'Time', 'StartPrice', 'MaxPrice', 'MinPrice', 'EndPrice', 'TradedVolume']\n",
        "    trg_key = 'xetra_daily_report_'\n",
        "    trg_format = '.parquet'\n",
        "    meta_key = 'aws-s3.csv'\n",
        "    \n",
        "    # Init\n",
        "    s3 = boto3.resource('s3', aws_access_key_id = '', \n",
        "                          aws_secret_access_key= '')\n",
        "    # run application\n",
        "    bucket_src = s3.Bucket(src_bucket)\n",
        "    bucket_trg = s3.Bucket(trg_bucket)\n",
        "    # run application\n",
        "    date_list = return_date_list(bucket_trg, arg_date, src_format)\n",
        "    etl_report1(bucket_src, bucket_trg, date_list, columns, arg_date, trg_key, trg_format, meta_key)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thkHwYCZe0SH"
      },
      "source": [
        "\n",
        "def read_csv_to_df(bucket,key,decoding='utf-8',sep=','):\n",
        "  print(\"Extracting key: {}\".format(key))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Run\n",
        "main()"
      ],
      "metadata": {
        "id": "Scn_A5kscScm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-eUyT5XjPzVa"
      },
      "source": [
        "bucket=s3.Bucket(src_bucket)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9V7Go1buj4xM"
      },
      "source": [
        "def csv_to_df(filename):\n",
        "  csv_obj=bucket.Object(key=filename).get().get('Body').read().decode('utf-8')\n",
        "  data=StringIO(csv_obj)\n",
        "  df=pd.read_csv(data,delimiter=',')\n",
        "  return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQOy54AZlqy1"
      },
      "source": [
        "df_all"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xU790sYNuNUX"
      },
      "source": [
        "arg_date='2021-05-07'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqFupj8UZzqc"
      },
      "source": [
        "csv_obj_columnname=bucket.Object(key=objects[0].key).get().get('Body').read().decode('utf-8')\n",
        "data=StringIO(csv_obj_columnname)\n",
        "df_init=pd.read_csv(data,delimiter=',')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 609
        },
        "id": "-UNXEfQ4cAUH",
        "outputId": "7685a01b-1ff2-4221-f58a-86ff82f2998d"
      },
      "source": [
        "columns=['ISIN', 'Date', 'Time', 'StartPrice', 'MaxPrice', 'MinPrice', 'EndPrice', 'TradedVolume']\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ISIN</th>\n",
              "      <th>Date</th>\n",
              "      <th>Time</th>\n",
              "      <th>StartPrice</th>\n",
              "      <th>MaxPrice</th>\n",
              "      <th>MinPrice</th>\n",
              "      <th>EndPrice</th>\n",
              "      <th>TradedVolume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AT0000A0E9W5</td>\n",
              "      <td>2021-03-15</td>\n",
              "      <td>08:00</td>\n",
              "      <td>22.120</td>\n",
              "      <td>22.120</td>\n",
              "      <td>22.120</td>\n",
              "      <td>22.120</td>\n",
              "      <td>1527</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>DE000A0DJ6J9</td>\n",
              "      <td>2021-03-15</td>\n",
              "      <td>08:00</td>\n",
              "      <td>53.850</td>\n",
              "      <td>53.850</td>\n",
              "      <td>53.500</td>\n",
              "      <td>53.500</td>\n",
              "      <td>508</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>DE000A0D6554</td>\n",
              "      <td>2021-03-15</td>\n",
              "      <td>08:00</td>\n",
              "      <td>22.240</td>\n",
              "      <td>22.240</td>\n",
              "      <td>22.180</td>\n",
              "      <td>22.180</td>\n",
              "      <td>5270</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>DE000A0D9PT0</td>\n",
              "      <td>2021-03-15</td>\n",
              "      <td>08:00</td>\n",
              "      <td>201.500</td>\n",
              "      <td>201.500</td>\n",
              "      <td>200.600</td>\n",
              "      <td>200.600</td>\n",
              "      <td>1744</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>DE000A0HN5C6</td>\n",
              "      <td>2021-03-15</td>\n",
              "      <td>08:00</td>\n",
              "      <td>38.950</td>\n",
              "      <td>39.060</td>\n",
              "      <td>38.890</td>\n",
              "      <td>39.050</td>\n",
              "      <td>28662</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>206907</th>\n",
              "      <td>DE000A0WMPJ6</td>\n",
              "      <td>2021-03-16</td>\n",
              "      <td>16:42</td>\n",
              "      <td>19.235</td>\n",
              "      <td>19.235</td>\n",
              "      <td>19.235</td>\n",
              "      <td>19.235</td>\n",
              "      <td>211</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>206908</th>\n",
              "      <td>DE0007164600</td>\n",
              "      <td>2021-03-16</td>\n",
              "      <td>16:43</td>\n",
              "      <td>103.020</td>\n",
              "      <td>103.020</td>\n",
              "      <td>103.020</td>\n",
              "      <td>103.020</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>206909</th>\n",
              "      <td>DE0007568578</td>\n",
              "      <td>2021-03-16</td>\n",
              "      <td>16:44</td>\n",
              "      <td>24.550</td>\n",
              "      <td>24.550</td>\n",
              "      <td>24.550</td>\n",
              "      <td>24.550</td>\n",
              "      <td>130</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>206910</th>\n",
              "      <td>DE0007664005</td>\n",
              "      <td>2021-03-16</td>\n",
              "      <td>16:44</td>\n",
              "      <td>266.600</td>\n",
              "      <td>266.600</td>\n",
              "      <td>266.600</td>\n",
              "      <td>266.600</td>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>206911</th>\n",
              "      <td>DE000A0TGJ55</td>\n",
              "      <td>2021-03-16</td>\n",
              "      <td>16:44</td>\n",
              "      <td>128.000</td>\n",
              "      <td>128.000</td>\n",
              "      <td>128.000</td>\n",
              "      <td>128.000</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>206912 rows Ã— 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                ISIN        Date   Time  ...  MinPrice  EndPrice  TradedVolume\n",
              "0       AT0000A0E9W5  2021-03-15  08:00  ...    22.120    22.120          1527\n",
              "1       DE000A0DJ6J9  2021-03-15  08:00  ...    53.500    53.500           508\n",
              "2       DE000A0D6554  2021-03-15  08:00  ...    22.180    22.180          5270\n",
              "3       DE000A0D9PT0  2021-03-15  08:00  ...   200.600   200.600          1744\n",
              "4       DE000A0HN5C6  2021-03-15  08:00  ...    38.890    39.050         28662\n",
              "...              ...         ...    ...  ...       ...       ...           ...\n",
              "206907  DE000A0WMPJ6  2021-03-16  16:42  ...    19.235    19.235           211\n",
              "206908  DE0007164600  2021-03-16  16:43  ...   103.020   103.020            20\n",
              "206909  DE0007568578  2021-03-16  16:44  ...    24.550    24.550           130\n",
              "206910  DE0007664005  2021-03-16  16:44  ...   266.600   266.600           500\n",
              "206911  DE000A0TGJ55  2021-03-16  16:44  ...   128.000   128.000             3\n",
              "\n",
              "[206912 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPQ2Ppg8PQQq",
        "outputId": "d7d9d90a-6526-4f22-9347-7a967faf6926"
      },
      "source": [
        "! pip install pyarrow"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.7/dist-packages (3.0.0)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.7/dist-packages (from pyarrow) (1.19.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wycHVbJGPdOj"
      },
      "source": [
        "Write to S3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYoT1ZVRQBE8"
      },
      "source": [
        "\n",
        "bucket_target=s3.Bucket(trg_bucket)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trg_bucket='inna030'\n",
        "s3 = boto3.resource('s3', aws_access_key_id = '', \n",
        "                          aws_secret_access_key= '')\n",
        "bucket_trg=s3.Bucket(trg_bucket)\n",
        "for i in bucket_tar.objects.all():\n",
        "  print(i.key)"
      ],
      "metadata": {
        "id": "0d81qYyHcUeB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uz5lgLqvbmTo"
      },
      "source": [
        "Reading the uploaded file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eI6fYgpOb1yw"
      },
      "source": [
        "prq_obj=bucket_tar.Object(key=i.key).get().get('Body').read()\n",
        "data=BytesIO(prq_obj)\n",
        "df_report=pd.read_parquet(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZtEW6NOniFOD"
      },
      "source": [
        "df_report"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zt_T8NuWKXSi",
        "outputId": "ccd078ab-af46-42ee-cd6c-5abd289965ea"
      },
      "source": [
        "%cd drive/My Drive/ETL"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/ETL\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vYa4jv-ILjnh",
        "outputId": "bfc50fc1-fda6-4569-d4c9-491c684fdc8f"
      },
      "source": [
        "! git clone https://github.com/inna030/ETL.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'ETL'...\n",
            "remote: Enumerating objects: 4, done.\u001b[K\n",
            "remote: Counting objects: 100% (4/4), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 4 (delta 0), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (4/4), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUwEguIAMR77",
        "outputId": "e854b2b1-cfea-45ec-a426-da70e63011a4"
      },
      "source": [
        "! git checkout -b develop"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: not a git repository (or any parent up to mount point /content)\n",
            "Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Oq_a1ogRBr-"
      },
      "source": [
        "S3.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGd5cGMcRAWR"
      },
      "source": [
        "\"\"\"Connector and methods accessing S3\"\"\"\n",
        "import os\n",
        "import boto3\n",
        "import logging"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPOXSkIcRBNv"
      },
      "source": [
        "class s3bucketconnector():\n",
        "  def __init__(self,access_key:str,secret_key:str,endpoint_url:str,bucket:str):\n",
        "    #Constructor for S3BucketConnector\n",
        "    self._logger=logging.getLogger(__name__)\n",
        "    self.endpoint_url=endpoint_url\n",
        "    self.session=boto3.Session(aws_access_key_id=,aws_scret_access_key=)\n",
        "    self._s3=self.session.resource(service_name='s3',endpoint_url=endpoint_url)\n",
        "    self._bucket=self._s3.Bucket(bucket)\n",
        "  \n",
        "  def list_files_in_prefix(self,prefix:str):\n",
        "    \"\"\"\n",
        "    Listing all files with a preix on the S3 bucket\n",
        "    :param prefix on the S3 bucket that should be filetered with\n",
        "\n",
        "    returns:\n",
        "      files:list of all the file names containing the prefix in the key\n",
        "    \"\"\"\n",
        "\n",
        "    files=[i.key for i in self._bucket.objects.filter(Prefix=prefix)]\n",
        "    return files\n",
        "  \n",
        "  def read_csv_to_df(self):\n",
        "    pass\n",
        "\n",
        "  def write_df_to_s3(self):\n",
        "    pass\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLPOzNZ-olIp"
      },
      "source": [
        "meta_process.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o59m3LtUohWs"
      },
      "source": [
        "'''Methods for processing the meta file'''\n",
        "\n",
        "class MetaProcess():\n",
        "  '''\n",
        "  class for working with the meta file\n",
        "  '''\n",
        "\n",
        "  @staticmethod\n",
        "  def update_meta_file():\n",
        "    pass\n",
        "\n",
        "  @staticmethod\n",
        "  def return_date_file():\n",
        "    pass  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FsQy6ACpQr3"
      },
      "source": [
        "Constants.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FuMSy5qWpSUB"
      },
      "source": [
        "'''\n",
        "File to store constants\n",
        "'''\n",
        "from enum import Enum\n",
        "\n",
        "class S3FileTypes(Enum):\n",
        "  '''\n",
        "  supported file types for S3BucketConnector\n",
        "  '''\n",
        "  CSV='csv'\n",
        "  PARQUET='parquet'\n",
        "\n",
        "class MetaProcessFormat(Enum):\n",
        "  '''\n",
        "  formation for MetaProcess Class\n",
        "  '''\n",
        "  META_DATE_FORMAT='%Y-%m-%d'\n",
        "  META_PROCESS_DATE_FORMAT='%Y-%m-%d %H:%M:%S'\n",
        "  META_SOURCE_DATE_COL='source_date'\n",
        "  META_PROCESS_COL='datetime_of_processing'\n",
        "  META_FILE_FORMAT='csv'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yB6bP4yBqNdV"
      },
      "source": [
        "Custom_exceptions.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFCpEnDHqQzR"
      },
      "source": [
        "'''Custom Exceptions'''\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XWT4IvU2qkPi"
      },
      "source": [
        "Transformer.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pd89fRdJqjU7"
      },
      "source": [
        "\"\"\"Xetra ETL Component\"\"\"\n",
        "from typing import NamedTuple\n",
        "import logging\n",
        "from xetra.common.s3 import S3BucketConnector\n",
        "\n",
        "class XetraSourceConfig(NamedTuple):\n",
        "    \"\"\"\n",
        "    Class for source configuration data\n",
        "\n",
        "    src_first_extract_date: determines the date for extracting the source\n",
        "    src_columns: source column names\n",
        "    src_col_date: column name for date in source\n",
        "    src_col_isin: column name for isin in source\n",
        "    src_col_time: column name for time in source\n",
        "    src_col_start_price: column name for starting price in source\n",
        "    src_col_min_price: column name for minimum price in source\n",
        "    src_col_max_price: column name for maximum price in source\n",
        "    src_col_traded_vol: column name for traded volumne in source\n",
        "    \"\"\"\n",
        "    self._logger=logging.getLogger(__name__)\n",
        "    src_first_extract_date: str\n",
        "    src_columns: list\n",
        "    src_col_date: str\n",
        "    src_col_isin: str\n",
        "    src_col_time: str\n",
        "    src_col_start_price: str\n",
        "    src_col_min_price: str\n",
        "    src_col_max_price: str\n",
        "    src_col_traded_vol: str\n",
        "\n",
        "\n",
        "class XetraTargetConfig(NamedTuple):\n",
        "    \"\"\"\n",
        "    Class for target configuration data\n",
        "\n",
        "    trg_col_isin: column name for isin in target\n",
        "    trg_col_date: column name for date in target\n",
        "    trg_col_op_price: column name for opening price in target\n",
        "    trg_col_clos_price: column name for closing price in target\n",
        "    trg_col_min_price: column name for minimum price in target\n",
        "    trg_col_max_price: column name for maximum price in target\n",
        "    trg_col_dail_trad_vol: column name for daily traded volume in target\n",
        "    trg_col_ch_prev_clos: column name for change to previous day's closing price in target\n",
        "    trg_key: basic key of target file\n",
        "    trg_key_date_format: date format of target file key\n",
        "    trg_format: file format of the target file\n",
        "    \"\"\"\n",
        "    trg_col_isin: str\n",
        "    trg_col_date: str\n",
        "    trg_col_op_price: str\n",
        "    trg_col_clos_price: str\n",
        "    trg_col_min_price: str\n",
        "    trg_col_max_price: str\n",
        "    trg_col_dail_trad_vol: str\n",
        "    trg_col_ch_prev_clos: str\n",
        "    trg_key: str\n",
        "    trg_key_date_format: str\n",
        "    trg_format: str\n",
        "\n",
        "class XetraETL():\n",
        "    \"\"\"\n",
        "    Reads the Xetra data, transforms and writes the transformed to target\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, s3_bucket_src: S3BucketConnector,\n",
        "                 s3_bucket_trg: S3BucketConnector, meta_key: str,\n",
        "                 src_args: XetraSourceConfig, trg_args: XetraTargetConfig):\n",
        "        \"\"\"\n",
        "        Constructor for XetraTransformer\n",
        "\n",
        "        :param s3_bucket_src: connection to source S3 bucket\n",
        "        :param s3_bucket_trg: connection to target S3 bucket\n",
        "        :param meta_key: used as self.meta_key -> key of meta file\n",
        "        :param src_args: NamedTouple class with source configuration data\n",
        "        :param trg_args: NamedTouple class with target configuration data\n",
        "        \"\"\"\n",
        "        self.s3_bucket_src = s3_bucket_src\n",
        "        self.s3_bucket_trg = s3_bucket_trg\n",
        "        self.meta_key = meta_key\n",
        "        self.src_args = src_args\n",
        "        self.trg_args = trg_args\n",
        "        self.extract_date =\n",
        "        self.extract_date_list =\n",
        "        self.meta_update_list = \n",
        "    \n",
        "    def extract(self):\n",
        "        pass\n",
        "\n",
        "    def transform_report1(self):\n",
        "        pass\n",
        "    \n",
        "    def load(self):\n",
        "        pass\n",
        "    \n",
        "    def etl_report1(self):\n",
        "        pass\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t86TgXkKv7nd"
      },
      "source": [
        "Run.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2eWTUmwhv8rH"
      },
      "source": [
        "import logging\n",
        "import logging.config\n",
        "\n",
        "def main():\n",
        "  \"\"\"entry point to run the xetra ETL job\"\"\"\n",
        "  #Parsing YAML file\n",
        "  config_path=''\n",
        "  config=yaml.safe_load(open(config_path))\n",
        "  #configure logging\n",
        "  log_config=config['logging']\n",
        "  logging.config.dictConfig(log_config)\n",
        "  logger=logging.getLogger(__name__)\n",
        "  logger.info(\"This is a test.\")\n",
        "if __name__=='__main__':\n",
        "  main()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ac_0B4K9wkB9"
      },
      "source": [
        "Config.yml"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHv1Gy0awned"
      },
      "source": [
        "#Logging configuration\n",
        "\n",
        "logging:\n",
        "  version:1\n",
        "  formatters:\n",
        "    xetra:\n",
        "      format: \"Xetra Transformer-%(asctime)s-%(levelname)s-%(message)s\"\n",
        "  handlers:\n",
        "    console:\n",
        "      class: logging.StreamHandler\n",
        "      formatter: xetra\n",
        "      level: DEBUG\n",
        "  root:\n",
        "    level: DEBUG\n",
        "    handlers: [console]\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2toFodw0N60"
      },
      "source": [
        "Bash"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N47lkEpZ0L8_"
      },
      "source": [
        "from xetra.common.constants import S3FileTypes\n",
        "exit()\n",
        "dir\n",
        "cd tests\n",
        "import sys\n",
        "for p in sys.path:print(p)\n",
        "\n",
        "from xetra.common.constants import S3FileTypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utB0-e8-E9zb"
      },
      "source": [
        "Test_s3.py"
      ]
    }
  ]
}