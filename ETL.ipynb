{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ETL.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9dBU0L9jV14K",
        "outputId": "cda0dad4-2625-492b-eea6-717afb828869"
      },
      "source": [
        "pip install pipenv"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pipenv\n",
            "  Downloading pipenv-2021.5.29-py2.py3-none-any.whl (3.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.9 MB 7.7 MB/s \n",
            "\u001b[?25hCollecting virtualenv-clone>=0.2.5\n",
            "  Downloading virtualenv_clone-0.5.6-py3-none-any.whl (6.6 kB)\n",
            "Collecting virtualenv\n",
            "  Downloading virtualenv-20.7.0-py2.py3-none-any.whl (5.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.3 MB 52.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from pipenv) (2021.5.30)\n",
            "Requirement already satisfied: pip>=18.0 in /usr/local/lib/python3.7/dist-packages (from pipenv) (21.1.3)\n",
            "Requirement already satisfied: setuptools>=36.2.1 in /usr/local/lib/python3.7/dist-packages (from pipenv) (57.2.0)\n",
            "Collecting backports.entry-points-selectable>=1.0.4\n",
            "  Downloading backports.entry_points_selectable-1.1.0-py2.py3-none-any.whl (6.2 kB)\n",
            "Collecting distlib<1,>=0.3.1\n",
            "  Downloading distlib-0.3.2-py2.py3-none-any.whl (338 kB)\n",
            "\u001b[K     |████████████████████████████████| 338 kB 59.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata>=0.12 in /usr/local/lib/python3.7/dist-packages (from virtualenv->pipenv) (4.6.1)\n",
            "Collecting platformdirs<3,>=2\n",
            "  Downloading platformdirs-2.2.0-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: filelock<4,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from virtualenv->pipenv) (3.0.12)\n",
            "Requirement already satisfied: six<2,>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from virtualenv->pipenv) (1.15.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.12->virtualenv->pipenv) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.12->virtualenv->pipenv) (3.7.4.3)\n",
            "Installing collected packages: platformdirs, distlib, backports.entry-points-selectable, virtualenv-clone, virtualenv, pipenv\n",
            "Successfully installed backports.entry-points-selectable-1.1.0 distlib-0.3.2 pipenv-2021.5.29 platformdirs-2.2.0 virtualenv-20.7.0 virtualenv-clone-0.5.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 752
        },
        "id": "ptiT7KEbV-bc",
        "outputId": "996e4017-adef-45c5-9749-f021115753f8"
      },
      "source": [
        "!pip install awscli"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting awscli\n",
            "  Downloading awscli-1.20.11-py3-none-any.whl (3.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.7 MB 6.6 MB/s \n",
            "\u001b[?25hCollecting colorama<0.4.4,>=0.2.5\n",
            "  Downloading colorama-0.4.3-py2.py3-none-any.whl (15 kB)\n",
            "Collecting docutils<0.16,>=0.10\n",
            "  Downloading docutils-0.15.2-py3-none-any.whl (547 kB)\n",
            "\u001b[K     |████████████████████████████████| 547 kB 41.0 MB/s \n",
            "\u001b[?25hCollecting botocore==1.21.11\n",
            "  Downloading botocore-1.21.11-py3-none-any.whl (7.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.8 MB 25.2 MB/s \n",
            "\u001b[?25hCollecting s3transfer<0.6.0,>=0.5.0\n",
            "  Downloading s3transfer-0.5.0-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 9.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: rsa<4.8,>=3.1.2 in /usr/local/lib/python3.7/dist-packages (from awscli) (4.7.2)\n",
            "Requirement already satisfied: PyYAML<5.5,>=3.10 in /usr/local/lib/python3.7/dist-packages (from awscli) (3.13)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore==1.21.11->awscli) (2.8.1)\n",
            "Collecting urllib3<1.27,>=1.25.4\n",
            "  Downloading urllib3-1.26.6-py2.py3-none-any.whl (138 kB)\n",
            "\u001b[K     |████████████████████████████████| 138 kB 60.9 MB/s \n",
            "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore==1.21.11->awscli) (1.15.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<4.8,>=3.1.2->awscli) (0.4.8)\n",
            "Installing collected packages: urllib3, jmespath, botocore, s3transfer, docutils, colorama, awscli\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: docutils\n",
            "    Found existing installation: docutils 0.17.1\n",
            "    Uninstalling docutils-0.17.1:\n",
            "      Successfully uninstalled docutils-0.17.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "requests 2.23.0 requires urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1, but you have urllib3 1.26.6 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed awscli-1.20.11 botocore-1.21.11 colorama-0.4.3 docutils-0.15.2 jmespath-0.10.0 s3transfer-0.5.0 urllib3-1.26.6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "urllib3"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64Uv0S5GaeH-",
        "outputId": "a8b188b7-157d-496f-b47b-09d79019c4c3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "lZl79x1scsdF",
        "outputId": "3b964ad3-6f78-4152-fde9-db4cedab79f6"
      },
      "source": [
        "'''import os\n",
        "!export AWS_SHARED_CREDENTIALS_FILE=/content/drive/My\\ Drive/config/awscli.ini\n",
        "path = \"/content/drive/My Drive/config/awscli.ini\"\n",
        "os.environ['AWS_SHARED_CREDENTIALS_FILE'] = path\n",
        "print(os.environ['AWS_SHARED_CREDENTIALS_FILE'])'''"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'import os\\n!export AWS_SHARED_CREDENTIALS_FILE=/content/drive/My\\\\ Drive/config/awscli.ini\\npath = \"/content/drive/My Drive/config/awscli.ini\"\\nos.environ[\\'AWS_SHARED_CREDENTIALS_FILE\\'] = path\\nprint(os.environ[\\'AWS_SHARED_CREDENTIALS_FILE\\'])'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04E64YukSeb8"
      },
      "source": [
        "import boto3\n",
        "\n",
        "BUCKET_NAME = 'deutsche-boerse-xetra-pds' # replace with your bucket name\n",
        "\n",
        "# enter authentication credentials\n",
        "s3 = boto3.resource('s3', aws_access_key_id = 'AKIAVBBSZGH55ZKPCY5M', \n",
        "                          aws_secret_access_key= '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')"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gAoXuGyej65a",
        "outputId": "7f8615aa-1408-40c2-95dd-c5daac26ed89"
      },
      "source": [
        "!aws s3 ls deutsche-boerse-xetra-pds/2017-08-01/ --no-sign-request"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2018-04-04 17:58:38        136 2017-08-01_BINS_XETR00.csv\n",
            "2018-04-04 17:58:38        136 2017-08-01_BINS_XETR01.csv\n",
            "2018-04-04 17:58:38        136 2017-08-01_BINS_XETR02.csv\n",
            "2018-04-04 17:58:38        136 2017-08-01_BINS_XETR03.csv\n",
            "2018-04-04 17:58:38        136 2017-08-01_BINS_XETR04.csv\n",
            "2018-04-04 17:58:38        136 2017-08-01_BINS_XETR05.csv\n",
            "2018-04-04 17:58:38        136 2017-08-01_BINS_XETR06.csv\n",
            "2018-04-04 17:58:38    1016188 2017-08-01_BINS_XETR07.csv\n",
            "2018-04-04 17:58:39     934078 2017-08-01_BINS_XETR08.csv\n",
            "2018-04-04 17:58:38     863130 2017-08-01_BINS_XETR09.csv\n",
            "2018-04-04 17:58:41     805186 2017-08-01_BINS_XETR10.csv\n",
            "2018-04-04 17:58:38     749942 2017-08-01_BINS_XETR11.csv\n",
            "2018-04-04 17:58:40     788177 2017-08-01_BINS_XETR12.csv\n",
            "2018-04-04 17:58:40    1054569 2017-08-01_BINS_XETR13.csv\n",
            "2018-04-04 17:58:39    1145654 2017-08-01_BINS_XETR14.csv\n",
            "2018-04-04 17:58:41     712217 2017-08-01_BINS_XETR15.csv\n",
            "2018-04-04 17:58:41        136 2017-08-01_BINS_XETR16.csv\n",
            "2018-04-04 17:58:41        136 2017-08-01_BINS_XETR17.csv\n",
            "2018-04-04 17:58:41        136 2017-08-01_BINS_XETR18.csv\n",
            "2018-04-04 17:58:40        886 2017-08-01_BINS_XETR19.csv\n",
            "2018-04-04 17:58:41        136 2017-08-01_BINS_XETR20.csv\n",
            "2018-04-04 17:58:41        136 2017-08-01_BINS_XETR21.csv\n",
            "2018-04-04 17:58:41        136 2017-08-01_BINS_XETR22.csv\n",
            "2018-04-04 17:58:41        136 2017-08-01_BINS_XETR23.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJRNVZBRkVHJ",
        "outputId": "9fd82ce8-c101-40e9-c7cc-2db2bf9086aa"
      },
      "source": [
        "\n",
        "\n",
        "!pip install boto3\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting boto3\n",
            "  Downloading boto3-1.18.11-py3-none-any.whl (131 kB)\n",
            "\u001b[?25l\r\u001b[K     |██▌                             | 10 kB 30.8 MB/s eta 0:00:01\r\u001b[K     |█████                           | 20 kB 24.6 MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 30 kB 17.5 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 40 kB 15.8 MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 51 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 61 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 71 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 81 kB 8.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 92 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 102 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 112 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 122 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 131 kB 7.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from boto3) (0.5.0)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3) (0.10.0)\n",
            "Requirement already satisfied: botocore<1.22.0,>=1.21.11 in /usr/local/lib/python3.7/dist-packages (from boto3) (1.21.11)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.22.0,>=1.21.11->boto3) (2.8.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.7/dist-packages (from botocore<1.22.0,>=1.21.11->boto3) (1.26.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.22.0,>=1.21.11->boto3) (1.15.0)\n",
            "Installing collected packages: boto3\n",
            "Successfully installed boto3-1.18.11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ybKLEj3H1aT",
        "outputId": "d8dc9e4d-ec51-4593-d84d-53a5c1a32d62"
      },
      "source": [
        "!pip install pandas"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.1)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.19.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkJXOlXXlWsw"
      },
      "source": [
        "from io import StringIO,BytesIO\n",
        "from datetime import datetime,timedelta"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VI1RA7dQyo2"
      },
      "source": [
        "import boto3"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdpbRSFkQ4uW"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJEgseShDVR1"
      },
      "source": [
        "def read_csv_to_df(bucket,key,decoding='utf-8',sep=','):\n",
        "  csv_obj=bucket.Object(key=key).get().get('Body').decode(docoding)\n",
        "  data=StringIO(csv_obj)\n",
        "  df=pd.read_csv(data,delimiter=sep)\n",
        "  return df\n",
        "\n",
        "meta_key='aws-s3.csv'\n",
        "bucket_name_trg='inna030'\n",
        "s3 = boto3.resource('s3', aws_access_key_id = 'AKIAVBBSZGH55ZKPCY5M', \n",
        "                          aws_secret_access_key= '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')\n",
        "bucket_trg=s3.Bucket(bucket_name_trg)\n",
        "df_meta=read_csv_to_df(bucket_trg,meta_key)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgyaxpaKEHB5"
      },
      "source": [
        "df_meta"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kn94RAH3FzYG"
      },
      "source": [
        "arg_date='2021-04-23'\n",
        "today_str='2021-04-25'\n",
        "src_format='%Y-%m-%d'\n",
        "min_date=datetime.strptime(arg_date,src_format).date()-timedelta(days=1)\n",
        "today=datetime.strptime(today_str,src_format).date()\n",
        "return_date_list=[(min_date+timedelta(days=x)) for x in range(0,today-min_date).days+1)]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KjLIAPquG-Py"
      },
      "source": [
        "return_date_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWhaiUsJLTNe"
      },
      "source": [
        "src_dates=set(pd.to_datetime(df_meta['source_date']).dt.date)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lka3QEMILt1q"
      },
      "source": [
        "src_dates"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WjVDsgoqdykI"
      },
      "source": [
        "Application Layer - not core"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NstXZEd2LvM5"
      },
      "source": [
        "def return_date_list(bucket,arg_date,src_format,meta_key):\n",
        "  min_date=datetime.strptime(arg_date,src_format).date()-timedelta(days=1)\n",
        "  today=datetime.today().date()\n",
        "  try:\n",
        "      df_meta=read_csv_to_df(bucket,meta_key)\n",
        "      dates=[(min_date+timedelta(days=x) for x in range(0,(today-min_date).days+1))]                  \n",
        "      src_dates=set(pd.to_datetime(df_meta['source_date'].dt.date))\n",
        "      dates_missing=set(return_date_list[1:])-src_dates\n",
        "    if dates_missing:   \n",
        "      min_date=min(set(dates[1:])-src_dates)-timedelta(days=1)\n",
        "      return_dates=[date.strfttime(src_format) for date in return_date_list if date >=min_date]\n",
        "      return_min_date=min_date+timedelta(days=1)).strftime(src_format)\n",
        "    else:\n",
        "      return_dates=[]\n",
        "      return_min_date=datetime(2200,1,1).date()\n",
        "  except bucket.session.client('s3').execptions.NoSuchKey:\n",
        "    return_date=[(min_date+timedelta(days=x)).strftime(src_format) for x in range(0,(today-min.date).days+1)]\n",
        "    return_min_date=arg_date\n",
        "  return return_min_date,return_date\n",
        "\n",
        "def update_meta_file(bucket,meta_key,extract_date_list):\n",
        "  df_new=pd.DateFrame(columns=['source_date','datetime_of_processing'])\n",
        "  df_new['source_date']=extract_date_list\n",
        "  df_new['datetime_of_porcessing']=datetime.today().strftime('%Y-%m-%d')\n",
        "  df_old=read_csv_to_df(bucket,meta_key)\n",
        "  df_all=pd.concat([df_old,df_new])\n",
        "  write_df_to_s3_csv(bucket,df_all,meta_key)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7_NKpiaL3ik"
      },
      "source": [
        "min_date"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0O5uIqIjL4W2"
      },
      "source": [
        "return_dates=[date.strftime(src_format) for date in return_date_list if date>=min_date]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6CRcm0i0MJCX"
      },
      "source": [
        "return_dates"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--WB4iEeMNnZ"
      },
      "source": [
        "return_min_date=arg_date"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5z-bOUEyxam8"
      },
      "source": [
        "Adapter Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfvQPICXrSX-"
      },
      "source": [
        "def read_csv_to_df(bucket,key,decoding='utf-8',sep=','):\n",
        "  csv_obj=bucket.Object(key=key).get().get('Body').read().decode(decoding)\n",
        "  data=StringIO(csv_obj)\n",
        "  df=pd.read_csv(data,delimiter=sep)\n",
        "  return df\n",
        "\n",
        "def write_df_to_s3(bucket,df,key):\n",
        "  out_buffer=BytesIO()\n",
        "  df_all.to_parquet(out_buffer,index=False)\n",
        "  bucket.put_object(Body=out_buffer.getvalue(),key=key)\n",
        "  return True\n",
        "\n",
        "\n",
        "def write_df_to_s3_csv(bucket,df,key):\n",
        "  out_buffer=BytesIO()\n",
        "  df_all.to_csv(out_buffer,index=False)\n",
        "  bucket.put_object(Body=out_buffer.getvalue(),key=key)\n",
        "  return True\n",
        "\n",
        "def list_files_in_prefix(bucket,prefix):\n",
        "  files=[i.key for i in bucket.objects.filter(Prefix=prefix)]\n",
        "  return files\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KDcX-1_1xh-9"
      },
      "source": [
        "Application Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inv_t2u6xjoR"
      },
      "source": [
        "def extract(bucket,date_list):\n",
        "  files=[key for date in date_list for key in list_file_in_prefix(bucket,date)]\n",
        "  df=pd.concat([read_csv_to_df(bucket,i) for i in files],ignore_index=True)\n",
        "  return df\n",
        "\n",
        "def transform_report1(df,columns):\n",
        "  df=df.loc[:,columns]\n",
        "  df.dropna(inplace=True)\n",
        "  df['opening_price']=df.sort_values('Time').groupby(['ISIN','Date']).['StartPrice'].transform('first') #Get opening price per ISIN and day\n",
        "  df['closing_price']=df.sort_values(by=['Time']).groupby(['ISIN','Date'])['StartPrice'].transform('last')\n",
        "  df=df.groupby(['ISIN','Date'],as_index=False).agg(opeing_price_eur=('opening_price','min'),closing_price_eur=('closing_price','min'),minimum_price_eur=('MinPrice','min'),maximum_price_eur=('MaxPrice','max'),daily_traded_volume=('TradeVolume','sum'))\n",
        "  #Aggregations\n",
        "  df['prev_closing_price']=df.sort_values(by=['Date']).groupby(['ISIN'])['closing_price_eur'].shift(1)\n",
        "  df['change_prev_closing_%']=(df['closing_price_eur']-df['prev_closing_price']/df['prev_closing_price']*100\n",
        "  df.drop(columns=['prev_closing_price'],inplace=True)\n",
        "  #Percent Change Prev Closing\n",
        "  df=df.round(decimals=2)\n",
        "  df=df[df.Date>=arg_date]\n",
        "  return df\n",
        "\n",
        "def load(bucket,df,trg_key,trg_format,meta_key,extract_date_list):\n",
        "  key=trg_key+datetime.today().strftime('%Y%m%d_%H%M%S')+trg_format\n",
        "  load(bucket,df,trg_key,trg_format)\n",
        "  write_df_to_s3(bucket,df,key)\n",
        "  update_meta_file(bucket,meta_key,extract_date_list)\n",
        "  return True\n",
        "\n",
        "def etl_report1(src_bucket,trg_bucket,date_list,columns,arg_date,trg_key,trg_format,meta_key):\n",
        "  df=extract(src_bucket,date_list)\n",
        "  df=transform_report1(df,columns,arg_date)\n",
        "  extract_date_list=[date for date in date_list if date>=arg_date]\n",
        "  load(trg_bucket,df,trg_key,trg_format,meta_key,extract_date_list)\n",
        "  return True\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LIIapCJt43wb"
      },
      "source": [
        "Application layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5VrVitVH42g0"
      },
      "source": [
        "def return_date_list(bucket,arg_date,src_format):\n",
        "  min_date=datetime.strptime(arg_date,src_format).date()-timedelta(days=1)\n",
        "  today=datetime.today().date()\n",
        "  return_date_list=[(min_date+timedelta(days=x)).strftime(src_format) for x in range(0,today-min_date).days+1)]\n",
        "  return return_date_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yK59vqXxyja"
      },
      "source": [
        "Main function entrypoint"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gsKMe7b3xx0k"
      },
      "source": [
        "def main():\n",
        "  #Parameters/Configurations\n",
        "  #Later read config\n",
        "  arg_date='2021-07-31'\n",
        "  src_format='%Y-%m-%d'\n",
        "  src_bucket='deutshe-boerse-xetra-pds'\n",
        "  trg_bucket='inna030'\n",
        "  columns=['ISIN', 'Date', 'Time', 'StartPrice', 'MaxPrice', 'MinPrice', 'EndPrice', 'TradedVolume']\n",
        "  trg_key='xetra_daily_report'\n",
        "  trg_format='.parquet'\n",
        "  meta_key='aws-s3.csv'\n",
        "  #Init\n",
        "  #Enter authentication credentials\n",
        "  s3 = boto3.resource('s3', aws_access_key_id = 'AKIAVBBSZGH55ZKPCY5M', \n",
        "                          aws_secret_access_key= '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')\n",
        "  bucket_src=s3.Bucket(src_bucket)\n",
        "  bucket_trg=s3.Bucket(trg_bucket)\n",
        "\n",
        "  #Run application\n",
        "  date_list=return_date_list(bucket_trg,arg_date,src_formate,meta_key)\n",
        "  etl_report1(bucket_src,bucket_trg,objects,columns,arg_date,trg_key, trg_format)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWIjrxRW7ZKv"
      },
      "source": [
        "#Run\n",
        "main()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rrckYmfOk2q"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-eUyT5XjPzVa"
      },
      "source": [
        "bucket=s3.Bucket(src_bucket)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9V7Go1buj4xM"
      },
      "source": [
        "def csv_to_df(filename):\n",
        "  csv_obj=bucket.Object(key=filename).get().get('Body').read().decode('utf-8')\n",
        "  data=StringIO(csv_obj)\n",
        "  df=pd.read_csv(data,delimiter=',')\n",
        "  return df"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQOy54AZlqy1"
      },
      "source": [
        "df_all"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xU790sYNuNUX"
      },
      "source": [
        "arg_date='2021-05-07'"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqFupj8UZzqc"
      },
      "source": [
        "csv_obj_columnname=bucket.Object(key=objects[0].key).get().get('Body').read().decode('utf-8')\n",
        "data=StringIO(csv_obj_columnname)\n",
        "df_init=pd.read_csv(data,delimiter=',')\n"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 609
        },
        "id": "-UNXEfQ4cAUH",
        "outputId": "7685a01b-1ff2-4221-f58a-86ff82f2998d"
      },
      "source": [
        "columns=['ISIN', 'Date', 'Time', 'StartPrice', 'MaxPrice', 'MinPrice', 'EndPrice', 'TradedVolume']\n"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ISIN</th>\n",
              "      <th>Date</th>\n",
              "      <th>Time</th>\n",
              "      <th>StartPrice</th>\n",
              "      <th>MaxPrice</th>\n",
              "      <th>MinPrice</th>\n",
              "      <th>EndPrice</th>\n",
              "      <th>TradedVolume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AT0000A0E9W5</td>\n",
              "      <td>2021-03-15</td>\n",
              "      <td>08:00</td>\n",
              "      <td>22.120</td>\n",
              "      <td>22.120</td>\n",
              "      <td>22.120</td>\n",
              "      <td>22.120</td>\n",
              "      <td>1527</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>DE000A0DJ6J9</td>\n",
              "      <td>2021-03-15</td>\n",
              "      <td>08:00</td>\n",
              "      <td>53.850</td>\n",
              "      <td>53.850</td>\n",
              "      <td>53.500</td>\n",
              "      <td>53.500</td>\n",
              "      <td>508</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>DE000A0D6554</td>\n",
              "      <td>2021-03-15</td>\n",
              "      <td>08:00</td>\n",
              "      <td>22.240</td>\n",
              "      <td>22.240</td>\n",
              "      <td>22.180</td>\n",
              "      <td>22.180</td>\n",
              "      <td>5270</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>DE000A0D9PT0</td>\n",
              "      <td>2021-03-15</td>\n",
              "      <td>08:00</td>\n",
              "      <td>201.500</td>\n",
              "      <td>201.500</td>\n",
              "      <td>200.600</td>\n",
              "      <td>200.600</td>\n",
              "      <td>1744</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>DE000A0HN5C6</td>\n",
              "      <td>2021-03-15</td>\n",
              "      <td>08:00</td>\n",
              "      <td>38.950</td>\n",
              "      <td>39.060</td>\n",
              "      <td>38.890</td>\n",
              "      <td>39.050</td>\n",
              "      <td>28662</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>206907</th>\n",
              "      <td>DE000A0WMPJ6</td>\n",
              "      <td>2021-03-16</td>\n",
              "      <td>16:42</td>\n",
              "      <td>19.235</td>\n",
              "      <td>19.235</td>\n",
              "      <td>19.235</td>\n",
              "      <td>19.235</td>\n",
              "      <td>211</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>206908</th>\n",
              "      <td>DE0007164600</td>\n",
              "      <td>2021-03-16</td>\n",
              "      <td>16:43</td>\n",
              "      <td>103.020</td>\n",
              "      <td>103.020</td>\n",
              "      <td>103.020</td>\n",
              "      <td>103.020</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>206909</th>\n",
              "      <td>DE0007568578</td>\n",
              "      <td>2021-03-16</td>\n",
              "      <td>16:44</td>\n",
              "      <td>24.550</td>\n",
              "      <td>24.550</td>\n",
              "      <td>24.550</td>\n",
              "      <td>24.550</td>\n",
              "      <td>130</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>206910</th>\n",
              "      <td>DE0007664005</td>\n",
              "      <td>2021-03-16</td>\n",
              "      <td>16:44</td>\n",
              "      <td>266.600</td>\n",
              "      <td>266.600</td>\n",
              "      <td>266.600</td>\n",
              "      <td>266.600</td>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>206911</th>\n",
              "      <td>DE000A0TGJ55</td>\n",
              "      <td>2021-03-16</td>\n",
              "      <td>16:44</td>\n",
              "      <td>128.000</td>\n",
              "      <td>128.000</td>\n",
              "      <td>128.000</td>\n",
              "      <td>128.000</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>206912 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                ISIN        Date   Time  ...  MinPrice  EndPrice  TradedVolume\n",
              "0       AT0000A0E9W5  2021-03-15  08:00  ...    22.120    22.120          1527\n",
              "1       DE000A0DJ6J9  2021-03-15  08:00  ...    53.500    53.500           508\n",
              "2       DE000A0D6554  2021-03-15  08:00  ...    22.180    22.180          5270\n",
              "3       DE000A0D9PT0  2021-03-15  08:00  ...   200.600   200.600          1744\n",
              "4       DE000A0HN5C6  2021-03-15  08:00  ...    38.890    39.050         28662\n",
              "...              ...         ...    ...  ...       ...       ...           ...\n",
              "206907  DE000A0WMPJ6  2021-03-16  16:42  ...    19.235    19.235           211\n",
              "206908  DE0007164600  2021-03-16  16:43  ...   103.020   103.020            20\n",
              "206909  DE0007568578  2021-03-16  16:44  ...    24.550    24.550           130\n",
              "206910  DE0007664005  2021-03-16  16:44  ...   266.600   266.600           500\n",
              "206911  DE000A0TGJ55  2021-03-16  16:44  ...   128.000   128.000             3\n",
              "\n",
              "[206912 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPQ2Ppg8PQQq",
        "outputId": "d7d9d90a-6526-4f22-9347-7a967faf6926"
      },
      "source": [
        "! pip install pyarrow"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.7/dist-packages (3.0.0)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.7/dist-packages (from pyarrow) (1.19.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wycHVbJGPdOj"
      },
      "source": [
        "Write to S3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYoT1ZVRQBE8"
      },
      "source": [
        "\n",
        "bucket_target=s3.Bucket(trg_bucket)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uz5lgLqvbmTo"
      },
      "source": [
        "Reading the uploaded file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "ct1elhjiblI4",
        "outputId": "a348cab4-2432-4728-c36d-0ffce9239539"
      },
      "source": [
        "trg_bucket='inna030'\n",
        "s3 = boto3.resource('s3', aws_access_key_id = 'AKIAVBBSZGH55ZKPCY5M', \n",
        "                          aws_secret_access_key= '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')\n",
        "bucket_trg=s3.Bucket(trg_bucket)\n",
        "for i in bucket_tar.objects.all():\n",
        "  print(i.key)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-8b6c91fc1910>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrg_bucket\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'inna030'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m s3 = boto3.resource('s3', aws_access_key_id = 'AKIAVBBSZGH55ZKPCY5M', \n\u001b[0m\u001b[1;32m      3\u001b[0m                           aws_secret_access_key= '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')\n\u001b[1;32m      4\u001b[0m \u001b[0mbucket_trg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ms3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBucket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrg_bucket\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbucket_tar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjects\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'boto3' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eI6fYgpOb1yw"
      },
      "source": [
        "prq_obj=bucket_tar.Object(key=i.key).get().get('Body').read()\n",
        "data=BytesIO(prq_obj)\n",
        "df_report=pd.read_parquet(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZtEW6NOniFOD"
      },
      "source": [
        "df_report"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zt_T8NuWKXSi",
        "outputId": "ccd078ab-af46-42ee-cd6c-5abd289965ea"
      },
      "source": [
        "%cd drive/My Drive/ETL"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/ETL\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vYa4jv-ILjnh",
        "outputId": "bfc50fc1-fda6-4569-d4c9-491c684fdc8f"
      },
      "source": [
        "! git clone https://github.com/inna030/ETL.git"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'ETL'...\n",
            "remote: Enumerating objects: 4, done.\u001b[K\n",
            "remote: Counting objects: 100% (4/4), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 4 (delta 0), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (4/4), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUwEguIAMR77",
        "outputId": "e854b2b1-cfea-45ec-a426-da70e63011a4"
      },
      "source": [
        "! git checkout -b develop"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: not a git repository (or any parent up to mount point /content)\n",
            "Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Oq_a1ogRBr-"
      },
      "source": [
        "S3.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGd5cGMcRAWR"
      },
      "source": [
        "\"\"\"Connector and methods accessing S3\"\"\"\n",
        "import os\n",
        "import boto3\n",
        "import logging"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPOXSkIcRBNv"
      },
      "source": [
        "class s3bucketconnector():\n",
        "  def __init__(self,access_key:str,secret_key:str,endpoint_url:str,bucket:str):\n",
        "    #Constructor for S3BucketConnector\n",
        "    self._logger=logging.getLogger(__name__)\n",
        "    self.endpoint_url=endpoint_url\n",
        "    self.session=boto3.Session(aws_access_key_id=,aws_scret_access_key=)\n",
        "    self._s3=self.session.resource(service_name='s3',endpoint_url=endpoint_url)\n",
        "    self._bucket=self._s3.Bucket(bucket)\n",
        "  \n",
        "  def list_files_in_prefix(self,prefix:str):\n",
        "    \"\"\"\n",
        "    Listing all files with a preix on the S3 bucket\n",
        "    :param prefix on the S3 bucket that should be filetered with\n",
        "\n",
        "    returns:\n",
        "      files:list of all the file names containing the prefix in the key\n",
        "    \"\"\"\n",
        "\n",
        "    files=[i.key for i in self._bucket.objects.filter(Prefix=prefix)]\n",
        "    return files\n",
        "  \n",
        "  def read_csv_to_df(self):\n",
        "    pass\n",
        "\n",
        "  def write_df_to_s3(self):\n",
        "    pass\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLPOzNZ-olIp"
      },
      "source": [
        "meta_process.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o59m3LtUohWs"
      },
      "source": [
        "'''Methods for processing the meta file'''\n",
        "\n",
        "class MetaProcess():\n",
        "  '''\n",
        "  class for working with the meta file\n",
        "  '''\n",
        "\n",
        "  @staticmethod\n",
        "  def update_meta_file():\n",
        "    pass\n",
        "\n",
        "  @staticmethod\n",
        "  def return_date_file():\n",
        "    pass  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FsQy6ACpQr3"
      },
      "source": [
        "Constants.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FuMSy5qWpSUB"
      },
      "source": [
        "'''\n",
        "File to store constants\n",
        "'''\n",
        "from enum import Enum\n",
        "\n",
        "class S3FileTypes(Enum):\n",
        "  '''\n",
        "  supported file types for S3BucketConnector\n",
        "  '''\n",
        "  CSV='csv'\n",
        "  PARQUET='parquet'\n",
        "\n",
        "class MetaProcessFormat(Enum):\n",
        "  '''\n",
        "  formation for MetaProcess Class\n",
        "  '''\n",
        "  META_DATE_FORMAT='%Y-%m-%d'\n",
        "  META_PROCESS_DATE_FORMAT='%Y-%m-%d %H:%M:%S'\n",
        "  META_SOURCE_DATE_COL='source_date'\n",
        "  META_PROCESS_COL='datetime_of_processing'\n",
        "  META_FILE_FORMAT='csv'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yB6bP4yBqNdV"
      },
      "source": [
        "Custom_exceptions.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFCpEnDHqQzR"
      },
      "source": [
        "'''Custom Exceptions'''\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XWT4IvU2qkPi"
      },
      "source": [
        "Transformer.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pd89fRdJqjU7"
      },
      "source": [
        "\"\"\"Xetra ETL Component\"\"\"\n",
        "from typing import NamedTuple\n",
        "import logging\n",
        "from xetra.common.s3 import S3BucketConnector\n",
        "\n",
        "class XetraSourceConfig(NamedTuple):\n",
        "    \"\"\"\n",
        "    Class for source configuration data\n",
        "\n",
        "    src_first_extract_date: determines the date for extracting the source\n",
        "    src_columns: source column names\n",
        "    src_col_date: column name for date in source\n",
        "    src_col_isin: column name for isin in source\n",
        "    src_col_time: column name for time in source\n",
        "    src_col_start_price: column name for starting price in source\n",
        "    src_col_min_price: column name for minimum price in source\n",
        "    src_col_max_price: column name for maximum price in source\n",
        "    src_col_traded_vol: column name for traded volumne in source\n",
        "    \"\"\"\n",
        "    self._logger=logging.getLogger(__name__)\n",
        "    src_first_extract_date: str\n",
        "    src_columns: list\n",
        "    src_col_date: str\n",
        "    src_col_isin: str\n",
        "    src_col_time: str\n",
        "    src_col_start_price: str\n",
        "    src_col_min_price: str\n",
        "    src_col_max_price: str\n",
        "    src_col_traded_vol: str\n",
        "\n",
        "\n",
        "class XetraTargetConfig(NamedTuple):\n",
        "    \"\"\"\n",
        "    Class for target configuration data\n",
        "\n",
        "    trg_col_isin: column name for isin in target\n",
        "    trg_col_date: column name for date in target\n",
        "    trg_col_op_price: column name for opening price in target\n",
        "    trg_col_clos_price: column name for closing price in target\n",
        "    trg_col_min_price: column name for minimum price in target\n",
        "    trg_col_max_price: column name for maximum price in target\n",
        "    trg_col_dail_trad_vol: column name for daily traded volume in target\n",
        "    trg_col_ch_prev_clos: column name for change to previous day's closing price in target\n",
        "    trg_key: basic key of target file\n",
        "    trg_key_date_format: date format of target file key\n",
        "    trg_format: file format of the target file\n",
        "    \"\"\"\n",
        "    trg_col_isin: str\n",
        "    trg_col_date: str\n",
        "    trg_col_op_price: str\n",
        "    trg_col_clos_price: str\n",
        "    trg_col_min_price: str\n",
        "    trg_col_max_price: str\n",
        "    trg_col_dail_trad_vol: str\n",
        "    trg_col_ch_prev_clos: str\n",
        "    trg_key: str\n",
        "    trg_key_date_format: str\n",
        "    trg_format: str\n",
        "\n",
        "class XetraETL():\n",
        "    \"\"\"\n",
        "    Reads the Xetra data, transforms and writes the transformed to target\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, s3_bucket_src: S3BucketConnector,\n",
        "                 s3_bucket_trg: S3BucketConnector, meta_key: str,\n",
        "                 src_args: XetraSourceConfig, trg_args: XetraTargetConfig):\n",
        "        \"\"\"\n",
        "        Constructor for XetraTransformer\n",
        "\n",
        "        :param s3_bucket_src: connection to source S3 bucket\n",
        "        :param s3_bucket_trg: connection to target S3 bucket\n",
        "        :param meta_key: used as self.meta_key -> key of meta file\n",
        "        :param src_args: NamedTouple class with source configuration data\n",
        "        :param trg_args: NamedTouple class with target configuration data\n",
        "        \"\"\"\n",
        "        self.s3_bucket_src = s3_bucket_src\n",
        "        self.s3_bucket_trg = s3_bucket_trg\n",
        "        self.meta_key = meta_key\n",
        "        self.src_args = src_args\n",
        "        self.trg_args = trg_args\n",
        "        self.extract_date =\n",
        "        self.extract_date_list =\n",
        "        self.meta_update_list = \n",
        "    \n",
        "    def extract(self):\n",
        "        pass\n",
        "\n",
        "    def transform_report1(self):\n",
        "        pass\n",
        "    \n",
        "    def load(self):\n",
        "        pass\n",
        "    \n",
        "    def etl_report1(self):\n",
        "        pass\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t86TgXkKv7nd"
      },
      "source": [
        "Run.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2eWTUmwhv8rH"
      },
      "source": [
        "import logging\n",
        "import logging.config\n",
        "\n",
        "def main():\n",
        "  \"\"\"entry point to run the xetra ETL job\"\"\"\n",
        "  #Parsing YAML file\n",
        "  config_path=''\n",
        "  config=yaml.safe_load(open(config_path))\n",
        "  #configure logging\n",
        "  log_config=config['logging']\n",
        "  logging.config.dictConfig(log_config)\n",
        "  logger=logging.getLogger(__name__)\n",
        "  logger.info(\"This is a test.\")\n",
        "if __name__=='__main__':\n",
        "  main()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ac_0B4K9wkB9"
      },
      "source": [
        "Config.yml"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHv1Gy0awned"
      },
      "source": [
        "#Logging configuration\n",
        "\n",
        "logging:\n",
        "  version:1\n",
        "  formatters:\n",
        "    xetra:\n",
        "      format: \"Xetra Transformer-%(asctime)s-%(levelname)s-%(message)s\"\n",
        "  handlers:\n",
        "    console:\n",
        "      class: logging.StreamHandler\n",
        "      formatter: xetra\n",
        "      level: DEBUG\n",
        "  root:\n",
        "    level: DEBUG\n",
        "    handlers: [console]\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2toFodw0N60"
      },
      "source": [
        "Bash"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N47lkEpZ0L8_"
      },
      "source": [
        "from xetra.common.constants import S3FileTypes\n",
        "exit()\n",
        "dir\n",
        "cd tests\n",
        "import sys\n",
        "for p in sys.path:print(p)\n",
        "\n",
        "from xetra.common.constants import S3FileTypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utB0-e8-E9zb"
      },
      "source": [
        "Test_s3.py"
      ]
    }
  ]
}